{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe7c3d3-b86e-43b6-9524-ac1862c5d372",
   "metadata": {},
   "source": [
    "# Exercise 7. K-means Clustering and Principal Component Analysis\n",
    "\n",
    "In this exercise, you will implement the **K-means** clustering algorithm and\n",
    "apply it to compress an image. In the second part, you will use principal\n",
    "component analysis to find a low-dimensional representation of face images.\n",
    "Before starting on the programming exercise, we strongly recommend watch-\n",
    "ing the video lectures and completing the review questions for the associated\n",
    "topics. For details see **ex7.pdf**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726faede-ba3f-4e8f-9d89-4880338935b1",
   "metadata": {},
   "source": [
    "We will implement a K-means class **```Kmeans```** mathematical concepts and algorithms without using any ML library then in the following section we will use it in the exercise 7 of the course.\n",
    "\n",
    "The class is split into multiple cells using **```jdc```** package so that notes can be written for learning and understanding. Complete implementation of the class is under **```src/unsupervised/kmeans.py```** module of this repository.\n",
    "\n",
    "Following cell declares the class **```Kmeans```** with its basic attributes and common utility members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022f4b58-1515-492f-bacf-f72942d73daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jdc\n",
    "import numpy as np\n",
    "import matplotlib.image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import src.utils.displaydata as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a07d1-670c-482c-bfc4-1bd7f37b2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans(object):\n",
    "    '''\n",
    "    K-means, PCA implementation.\n",
    "    '''\n",
    "    def __init__(self, X):\n",
    "        '''\n",
    "        Initialize instance parameters.\n",
    "    \n",
    "        Arguments:\n",
    "          X (m x n float matrix): Data matrix.\n",
    "        '''\n",
    "        self.X = X\n",
    "        self.mu = None\n",
    "        self.sigma = None\n",
    "        self._colors = None\n",
    "    \n",
    "    \n",
    "    def kmeans_init_centroids(self, K):\n",
    "        '''\n",
    "        Initialize and return K centroids that are to\n",
    "        be used in K-Means on the dataset X.\n",
    "    \n",
    "        Arguments:\n",
    "          K (int): Number of centroids.\n",
    "    \n",
    "        Return:\n",
    "          (K x X.shape[1]) Centroids values.\n",
    "        '''\n",
    "        # Initialize the centroids to be random examples.\n",
    "        # Randomly reorder the indices of examples.\n",
    "        rand_idx = np.random.permutation(self.X.shape[0])\n",
    "        # Take the first K examples as centroids\n",
    "        centroids = self.X[rand_idx[:K],:]\n",
    "        return centroids\n",
    "    \n",
    "    \n",
    "    def kmeans_showprogress(self, centroids,  iter, \n",
    "                                  plt_progress=False):\n",
    "        '''\n",
    "        Compute K-Means algorithm and plot progress.\n",
    "    \n",
    "        Arguments:\n",
    "          centroids (m x n float matrix): Centroids values.\n",
    "          iter (int): Max number of iterations.\n",
    "          plt_progress (Boolean): 'True' if show progress on the graph.\n",
    "    \n",
    "        Returns:\n",
    "          ci (m x n float matrix): Centroid values.\n",
    "          cc (int vector): The indices of the closest centroids.\n",
    "        '''\n",
    "        K = centroids.shape[0]\n",
    "        self._colors = cm.rainbow(np.linspace(0, 1, K))\n",
    "        cc = None\n",
    "    \n",
    "        for i in range(iter):\n",
    "          # For each example in X, assign it to the\n",
    "          # closest centroid.\n",
    "          cc = self.closest_centroid(centroids);\n",
    "    \n",
    "          if plt_progress:\n",
    "            self._plot_progress_kmeans(centroids, cc, K, i)\n",
    "          centroids = self.centroids_means(cc, K)\n",
    "        return centroids, cc.astype(int)\n",
    "    \n",
    "    \n",
    "    def closest_centroid(self, centroids):\n",
    "        '''\n",
    "        Compute the closest centroid memberships for every example.\n",
    "    \n",
    "        Arguments:\n",
    "          centroids (m x n float matrix): Centroid values.\n",
    "    \n",
    "        Return:\n",
    "          cc (int vector): The indices of the closest centroids.\n",
    "        '''\n",
    "        ci = np.zeros((self.X.shape[0], 1))\n",
    "    \n",
    "        for i, xi in enumerate(self.X):\n",
    "          mod_list = []\n",
    "          for c in centroids:\n",
    "            mod_list.append(np.sqrt(np.sum((xi - c) ** 2)))\n",
    "          ci[i] = np.argmin(mod_list)\n",
    "        return ci.astype(int)\n",
    "    \n",
    "    \n",
    "    def centroids_means(self, ci, K):\n",
    "        '''\n",
    "        Compute means based on the closest centroids.\n",
    "    \n",
    "        Computes the new centroids by computing the means\n",
    "        of the data points assigned to each centroid.\n",
    "    \n",
    "        Arguments:\n",
    "          ci (int vector): A vector of centroid indices assignments.\n",
    "          K (int): Number of dimensions.\n",
    "    \n",
    "        Return:\n",
    "          (m x n float matrix): Mean calculated centroids.\n",
    "        '''\n",
    "        m = self.X.shape[0]\n",
    "        n = self.X.shape[1]\n",
    "        centroids = np.zeros((K, n))\n",
    "    \n",
    "        for k in range(K):\n",
    "          xi_idx = np.where(ci[:,0] == k)[0]\n",
    "          centroids[k,:] = np.sum(self.X[xi_idx,:], axis=0) / len(xi_idx)\n",
    "        return centroids\n",
    "      \n",
    "    \n",
    "    def pca(self, norm_first=True):\n",
    "        '''\n",
    "        Compute Principal Component Analysis on the dataset X.\n",
    "    \n",
    "        Computes eigenvectors of the covariance matrix of X \n",
    "        returns the eigenvectors U, the eigenvalues (on diagonal)\n",
    "        in s.\n",
    "    \n",
    "        Arguments:\n",
    "          norm_first (Boolean): 'True' if normalize data before processing.\n",
    "    \n",
    "        Return:\n",
    "          U, Unitary matrices.\n",
    "          s, The singular values for every matrix, sorted in descending order.\n",
    "        '''\n",
    "        m = self.X.shape[0]\n",
    "        X_norm = self.X\n",
    "    \n",
    "        # First compute the covariance matrix.\n",
    "        if norm_first:\n",
    "          X_norm = self._normalize()\n",
    "        cov_mat = X_norm.transpose().dot(X_norm) / m\n",
    "    \n",
    "        # Compute the eigenvectors and eigenvalues\n",
    "        # of the covariance matrix.\n",
    "        U, s, V  = np.linalg.svd(cov_mat, full_matrices=True)\n",
    "        return U, s\n",
    "    \n",
    "    \n",
    "    def project_data(self, X_norm, U, K):\n",
    "        '''\n",
    "        Project data to 'K' dimensions.\n",
    "    \n",
    "        Arguments:\n",
    "          U (m x n float matrix): Unitary matrices.\n",
    "          K (int): Number of dimensions.\n",
    "    \n",
    "        Return:\n",
    "          Projected matrix to the 'K' dimensions.\n",
    "        '''\n",
    "        Z = np.zeros((X_norm.shape[0], K))\n",
    "        for i in range(X_norm.shape[0]):\n",
    "          xi = X_norm[[i],:]\n",
    "          Z[i,:] = xi.dot(U[:,:K])\n",
    "        return Z\n",
    "    \n",
    "    \n",
    "    def recover_data(self, Z, U, K):\n",
    "        '''\n",
    "        Recover data from 'K' dimension back to\n",
    "        original dimensions.\n",
    "    \n",
    "        Arguments:\n",
    "          Z (m x n float matrix): Projected dimensions.\n",
    "          U (m x n float matrix): Unitary matrices.\n",
    "          K (int): Number of dimensions.\n",
    "    \n",
    "        Return:\n",
    "          Recovered matrix to the original dimensions.\n",
    "        '''\n",
    "        X_rec = np.zeros((Z.shape[0], U.shape[0]))\n",
    "        for i in range(Z.shape[0]):\n",
    "          zi = Z[[i],:].transpose()\n",
    "          for j in range(U.shape[0]):\n",
    "            X_rec[i,j] = zi.transpose().dot((U[[j],:K]).transpose())[0][0]\n",
    "        return X_rec\n",
    "    \n",
    "    \n",
    "    def plot_data_set(self, X, title_label='', x_label='', y_label=''):\n",
    "        '''\n",
    "        Plot data points.\n",
    "    \n",
    "        Arguments:\n",
    "          X (m x n float matrix): Data points.\n",
    "          title_label (str): Title label.\n",
    "          x_label (str): X-axis label.\n",
    "          y_label (str): Y-axis label.\n",
    "        '''\n",
    "        plt.title(title_label)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.plot(X[:, 0], X[:, 1], 'bo')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_pca_vector(self, p1, p2, xlim, ylim):\n",
    "        '''\n",
    "        Plot PCA vector.\n",
    "    \n",
    "        Arguments:\n",
    "          p1 (float pair): Point 1.\n",
    "          p2 (float pair): Point 2.\n",
    "          xlim (float pair): x-axis limit.\n",
    "          ylim (float pair): y-axis limit.\n",
    "        '''\n",
    "        plt.title('Computed eigenvectors of the dataset')\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylim(ylim)\n",
    "        plt.plot(self.X[:,0], self.X[:,1], 'bo')\n",
    "        plt.plot([p1[0], p2[0]], [p1[1], p2[1]])\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def _normalize(self):\n",
    "        '''\n",
    "        Normalized version of X where the mean value\n",
    "        of each feature is 0 and the standard deviation is 1. \n",
    "        This is often a good preprocessing step to do when\n",
    "        working with learning algorithms.\n",
    "        '''\n",
    "        #self.mu = np.mean(self.X)\n",
    "        #self.sigma = np.std(self.X)\n",
    "        #X_norm = (self.X - self.mu) / self.sigma\n",
    "    \n",
    "        self.mu = np.mean(self.X, axis=0)\n",
    "        self.sigma = np.std(self.X, axis=0)\n",
    "    \n",
    "        X_norm = np.zeros_like(self.X)\n",
    "        for j in range(self.X.shape[1]):\n",
    "          X_norm[:,j] = (self.X[:,j] - self.mu[j]) / self.sigma[j]\n",
    "        return X_norm\n",
    "    \n",
    "    \n",
    "    def _plot_progress_kmeans(self, centroids, closes_centroids, K, i):\n",
    "        '''\n",
    "        Plots kMeans data, 2d only.\n",
    "    \n",
    "        Arguments:\n",
    "          centroids (m x n): Centroids matrix.\n",
    "          closest_centroids (vector): Closest centroids.\n",
    "          K (int): Dimensions.\n",
    "          i (int): Index of iteration.\n",
    "        '''\n",
    "        for k, c in zip(list(range(K)), self._colors):\n",
    "          plt.scatter(self.X[np.where(closes_centroids == k),0], \n",
    "                      self.X[np.where(closes_centroids == k),1],\n",
    "                      15, color=c)\n",
    "    \n",
    "        # Plot the centroids as black x's\n",
    "        plt.plot(centroids[:,0], centroids[:,1],\n",
    "                 marker='x', color='black')\n",
    "        plt.title('Iteration number {}'.format(i))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d9061-3ed7-4206-b273-9af7a19c65c4",
   "metadata": {},
   "source": [
    "# Coming Soon..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af87f18-33db-4cf7-97ce-176965fef40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
